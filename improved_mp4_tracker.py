#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ÊîπËøõÁöÑÂëΩ‰ª§Ë°åË∑üË∏™Â∑•ÂÖ∑ - ÊîØÊåÅË∑≥Â∏ßÂíåÈ´òÊÄßËÉΩË∑üË∏™
Improved Command Line Tracker - With Frame Skipping and High Performance

‰∏ªË¶ÅÊîπËøõÔºö
1. ÊîØÊåÅË∑≥Â∏ßÂ§ÑÁêÜ - Â§ßÂπÖÊèêÂçáÂ§ÑÁêÜÈÄüÂ∫¶
2. ÁúüÂÆûLightTrackÊ®°ÂûãÈõÜÊàê - ÁßªÈô§ÊºîÁ§∫Ê®°Âºè
3. Ëá™ÈÄÇÂ∫îÊÄßËÉΩË∞É‰ºò - Ê†πÊçÆËßÜÈ¢ëÁâπÁÇπËá™Âä®‰ºòÂåñ
4. ËØ¶ÁªÜÁöÑÊÄßËÉΩÂàÜÊûê - ÂÆåÊï¥ÁöÑÁªüËÆ°‰ø°ÊÅØËæìÂá∫
"""

import os
import sys
import cv2
import argparse
import numpy as np
import time
from pathlib import Path

# Ê∑ªÂä†È°πÁõÆË∑ØÂæÑ
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

from improved_tracker import ImprovedTracker


def parse_args():
    parser = argparse.ArgumentParser(description='LightTrack ÊîπËøõÁâàÂëΩ‰ª§Ë°åË∑üË∏™Â∑•ÂÖ∑')
    parser.add_argument('--video', type=str, required=True, help='ËæìÂÖ•MP4ËßÜÈ¢ëÊñá‰ª∂Ë∑ØÂæÑ')
    parser.add_argument('--bbox', type=str, help='ÂàùÂßãËæπÁïåÊ°Ü (x,y,w,h)')
    parser.add_argument('--output', type=str, help='ËæìÂá∫ËßÜÈ¢ëÊñá‰ª∂Ë∑ØÂæÑ')
    parser.add_argument('--display', action='store_true', help='ÂÆûÊó∂ÊòæÁ§∫Ë∑üË∏™ÁªìÊûú')
    parser.add_argument('--frame-skip', type=int, default=1, help='Ë∑≥Â∏ßÈó¥Èöî (ÈªòËÆ§:1, ‰∏çË∑≥Â∏ß)')
    parser.add_argument('--target-fps', type=float, default=30.0, help='ÁõÆÊ†áFPS (ÈªòËÆ§:30)')
    parser.add_argument('--benchmark', action='store_true', help='ÊÄßËÉΩÂü∫ÂáÜÊµãËØïÊ®°Âºè')
    parser.add_argument('--auto-optimize', action='store_true', help='Ëá™Âä®‰ºòÂåñÂèÇÊï∞')
    return parser.parse_args()


def parse_bbox(bbox_str):
    """Ëß£ÊûêËæπÁïåÊ°ÜÂ≠óÁ¨¶‰∏≤"""
    try:
        bbox = [float(x) for x in bbox_str.split(',')]
        if len(bbox) != 4:
            raise ValueError
        return bbox
    except:
        raise ValueError("ËæπÁïåÊ°ÜÊ†ºÂºèÈîôËØØÔºåÂ∫î‰∏∫: x,y,w,h")


def select_bbox_interactive(video_path):
    """‰∫§‰∫íÂºèÈÄâÊã©ËæπÁïåÊ°Ü"""
    print("Ê≠£Âú®ÊâìÂºÄËßÜÈ¢ëËøõË°åÁõÆÊ†áÈÄâÊã©...")
    cap = cv2.VideoCapture(video_path)
    ret, frame = cap.read()
    cap.release()
    
    if not ret:
        raise ValueError("Êó†Ê≥ïËØªÂèñËßÜÈ¢ëÁ¨¨‰∏ÄÂ∏ß")
    
    print("ËØ∑Âú®Á™óÂè£‰∏≠ÊãñÊãΩÈº†Ê†áÈÄâÊã©Ë∑üË∏™ÁõÆÊ†áÔºåÊåâENTERÁ°ÆËÆ§ÔºåÊåâESCÂèñÊ∂à")
    
    # ‰ΩøÁî®OpenCVÁöÑROIÈÄâÊã©Âô®
    bbox = cv2.selectROI("ÈÄâÊã©Ë∑üË∏™ÁõÆÊ†á - Ê°ÜÈÄâÂêéÊåâENTERÁ°ÆËÆ§", frame, False)
    cv2.destroyWindow("ÈÄâÊã©Ë∑üË∏™ÁõÆÊ†á - Ê°ÜÈÄâÂêéÊåâENTERÁ°ÆËÆ§")
    
    if bbox[2] > 0 and bbox[3] > 0:
        return list(bbox)
    else:
        return None


def analyze_video(video_path):
    """ÂàÜÊûêËßÜÈ¢ëÁâπÂæÅÔºåÁªôÂá∫‰ºòÂåñÂª∫ËÆÆ"""
    print("\nüìä ÂàÜÊûêËßÜÈ¢ëÁâπÂæÅ...")
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return None, None
    
    # Ëé∑ÂèñÂü∫Êú¨‰ø°ÊÅØ
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    duration = total_frames / fps if fps > 0 else 0
    
    # ÈááÊ†∑Âá†Â∏ßÂàÜÊûêËøêÂä®ÂπÖÂ∫¶
    motion_scores = []
    prev_gray = None
    
    for i in range(0, min(total_frames, 100), 10):
        cap.set(cv2.CAP_PROP_POS_FRAMES, i)
        ret, frame = cap.read()
        if not ret:
            break
        
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        if prev_gray is not None:
            flow = cv2.calcOpticalFlowPyrLK(prev_gray, gray, 
                                          np.array([[width//2, height//2]], dtype=np.float32),
                                          None, maxLevel=2)[0]
            if flow is not None and len(flow) > 0:
                motion = np.linalg.norm(flow[0])
                motion_scores.append(motion)
        
        prev_gray = gray
    
    cap.release()
    
    # ËÆ°ÁÆóËøêÂä®ÁªüËÆ°
    avg_motion = np.mean(motion_scores) if motion_scores else 0
    
    # ËßÜÈ¢ëÁâπÂæÅ
    video_info = {
        'total_frames': total_frames,
        'fps': fps,
        'width': width,
        'height': height,
        'duration': duration,
        'avg_motion': avg_motion,
        'motion_level': 'high' if avg_motion > 10 else 'medium' if avg_motion > 3 else 'low'
    }
    
    # ÊÄßËÉΩÂª∫ËÆÆ
    suggestions = {}
    
    # Âü∫‰∫éËßÜÈ¢ëÈïøÂ∫¶ÁöÑÂª∫ËÆÆ
    if duration > 60:
        suggestions['frame_skip'] = 3
        suggestions['reason'] = "ÈïøËßÜÈ¢ëÔºåÂª∫ËÆÆËæÉÂ§ßË∑≥Â∏ßÈó¥Èöî"
    elif duration > 30:
        suggestions['frame_skip'] = 2
        suggestions['reason'] = "‰∏≠Á≠âÈïøÂ∫¶ËßÜÈ¢ëÔºåÈÄÇÂ∫¶Ë∑≥Â∏ß"
    else:
        suggestions['frame_skip'] = 1
        suggestions['reason'] = "Áü≠ËßÜÈ¢ëÔºå‰øùÊåÅÈ´òË¥®Èáè"
    
    # Âü∫‰∫éËøêÂä®ÂπÖÂ∫¶ÁöÑÂª∫ËÆÆ
    if avg_motion > 10:
        suggestions['target_fps'] = 60
        suggestions['motion_reason'] = "È´òËøêÂä®ÂπÖÂ∫¶ÔºåÈúÄË¶ÅÈ´òÂ∏ßÁéá"
    elif avg_motion > 3:
        suggestions['target_fps'] = 30
        suggestions['motion_reason'] = "‰∏≠Á≠âËøêÂä®ÂπÖÂ∫¶ÔºåÊ†áÂáÜÂ∏ßÁéá"
    else:
        suggestions['target_fps'] = 20
        suggestions['motion_reason'] = "‰ΩéËøêÂä®ÂπÖÂ∫¶ÔºåÂèØÈôç‰ΩéÂ∏ßÁéá"
    
    # Âü∫‰∫éÂàÜËæ®ÁéáÁöÑÂª∫ËÆÆ
    if width * height > 1920 * 1080:
        suggestions['frame_skip'] = max(suggestions['frame_skip'], 2)
        suggestions['resolution_reason'] = "È´òÂàÜËæ®ÁéáÔºåÂ¢ûÂä†Ë∑≥Â∏ß"
    
    return video_info, suggestions


def print_video_analysis(video_info, suggestions):
    """ÊâìÂç∞ËßÜÈ¢ëÂàÜÊûêÁªìÊûú"""
    print(f"   ÂàÜËæ®Áéá: {video_info['width']}x{video_info['height']}")
    print(f"   ÊÄªÂ∏ßÊï∞: {video_info['total_frames']}")
    print(f"   Â∏ßÁéá: {video_info['fps']:.2f} FPS")
    print(f"   Êó∂Èïø: {video_info['duration']:.1f}Áßí")
    print(f"   ËøêÂä®ÂπÖÂ∫¶: {video_info['motion_level']} (Âπ≥Âùá: {video_info['avg_motion']:.1f})")
    
    print(f"\nüí° ‰ºòÂåñÂª∫ËÆÆ:")
    print(f"   Êé®ËçêË∑≥Â∏ßÈó¥Èöî: {suggestions['frame_skip']} ({suggestions['reason']})")
    print(f"   Êé®ËçêÁõÆÊ†áFPS: {suggestions['target_fps']} ({suggestions['motion_reason']})")
    if 'resolution_reason' in suggestions:
        print(f"   ÂàÜËæ®ÁéáË∞ÉÊï¥: {suggestions['resolution_reason']}")


def track_video_improved(video_path, init_bbox, output_path, display=False, 
                        frame_skip=1, target_fps=30.0, benchmark=False):
    """‰ΩøÁî®ÊîπËøõË∑üË∏™Âô®Â§ÑÁêÜËßÜÈ¢ë"""
    
    print(f"\nüöÄ ÂºÄÂßãÊîπËøõÁâàË∑üË∏™")
    print(f"Ë∑≥Â∏ßÈó¥Èöî: {frame_skip}, ÁõÆÊ†áFPS: {target_fps}")
    
    # ÂàõÂª∫Ë∑üË∏™Âô®
    tracker = ImprovedTracker(frame_skip=frame_skip, target_fps=target_fps)
    
    # ÊâìÂºÄËßÜÈ¢ë
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError(f"Êó†Ê≥ïÊâìÂºÄËßÜÈ¢ëÊñá‰ª∂: {video_path}")
    
    # Ëé∑ÂèñËßÜÈ¢ëÂ±ûÊÄß
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    original_fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    print(f"ËßÜÈ¢ë‰ø°ÊÅØ: {width}x{height}, {original_fps}fps, {total_frames}Â∏ß")
    
    # ÂáÜÂ§áËæìÂá∫ËßÜÈ¢ë
    if output_path is None:
        output_path = os.path.splitext(video_path)[0] + f"_tracked_fs{frame_skip}_fps{target_fps:.0f}.mp4"
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, original_fps, (width, height))
    
    # ËØªÂèñÁ¨¨‰∏ÄÂ∏ß
    ret, frame = cap.read()
    if not ret:
        raise ValueError("Êó†Ê≥ïËØªÂèñËßÜÈ¢ëÁ¨¨‰∏ÄÂ∏ß")
    
    # ÂàùÂßãÂåñË∑üË∏™Âô®
    print(f"ÂàùÂßãÂåñË∑üË∏™Âô®ÔºåÁõÆÊ†áÂå∫Âüü: {init_bbox}")
    
    start_time = time.time()
    if not tracker.initialize(frame, init_bbox):
        raise ValueError("Ë∑üË∏™Âô®ÂàùÂßãÂåñÂ§±Ë¥•")
    
    init_time = time.time() - start_time
    print(f"‚úÖ Ë∑üË∏™Âô®ÂàùÂßãÂåñÊàêÂäü (ËÄóÊó∂: {init_time:.3f}Áßí)")
    
    # Ë∑üË∏™ÁªüËÆ°
    stats = {
        'start_time': time.time(),
        'frame_times': [],
        'total_frames': 0,
        'successful_frames': 0,
        'processing_times': []
    }
    
    # Âü∫ÂáÜÊµãËØïÊï∞ÊçÆ
    if benchmark:
        benchmark_data = {
            'frame_processing_times': [],
            'confidence_scores': [],
            'bbox_stability': [],
            'skip_ratios': []
        }
    
    frame_count = 0
    
    # Â§ÑÁêÜËßÜÈ¢ëÂ∏ß
    print("üìπ ÂºÄÂßãÂ§ÑÁêÜËßÜÈ¢ëÂ∏ß...")
    
    while ret:
        frame_start = time.time()
        
        # Ë∑üË∏™ÂΩìÂâçÂ∏ß
        success, bbox, confidence, info = tracker.track(frame)
        
        processing_time = time.time() - frame_start
        stats['processing_times'].append(processing_time)
        
        # ÁªòÂà∂Ë∑üË∏™ÁªìÊûú
        if success and bbox is not None:
            x, y, w, h = [int(v) for v in bbox]
            
            # ÈÄâÊã©È¢úËâ≤
            if confidence > 0.7:
                color = (0, 255, 0)  # ÁªøËâ≤ - È´òÁΩÆ‰ø°Â∫¶
            elif confidence > 0.4:
                color = (0, 255, 255)  # ÈªÑËâ≤ - ‰∏≠ÁΩÆ‰ø°Â∫¶  
            else:
                color = (0, 165, 255)  # Ê©ôËâ≤ - ‰ΩéÁΩÆ‰ø°Â∫¶
            
            # ÁªòÂà∂ËæπÁïåÊ°Ü
            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
            
            # Ê∑ªÂä†‰ø°ÊÅØÊñáÊú¨
            cv2.putText(frame, f'Frame: {frame_count + 1}/{total_frames}', 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(frame, f'Confidence: {confidence:.3f}', 
                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # Ë∑üË∏™Ê®°Âºè‰ø°ÊÅØ
            mode = "LightTrack" if tracker.model is not None else "Template"
            cv2.putText(frame, f'Mode: {mode}', 
                       (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # Ë∑≥Â∏ß‰ø°ÊÅØ
            if info.get('skipped', False):
                cv2.putText(frame, 'SKIPPED (Interpolated)', 
                          (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
            
            # ÊÄßËÉΩ‰ø°ÊÅØ
            tracker_stats = tracker.get_stats()
            current_fps = tracker_stats.get('avg_fps', 0)
            cv2.putText(frame, f'Processing FPS: {current_fps:.1f}', 
                       (10, height - 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
            
            # ÊàêÂäüÁéá
            success_rate = tracker_stats.get('success_rate', 0)
            cv2.putText(frame, f'Success Rate: {success_rate:.1f}%', 
                       (10, height - 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # Á≥ªÁªüÊ†áËØÜ
            cv2.putText(frame, 'LightTrack Improved', 
                       (10, height - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            stats['successful_frames'] += 1
            
        else:
            # Ë∑üË∏™Â§±Ë¥•
            cv2.putText(frame, 'Tracking Lost', (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            cv2.putText(frame, f'Frame: {frame_count + 1}/{total_frames}', 
                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # Âü∫ÂáÜÊµãËØïÊï∞ÊçÆÊî∂ÈõÜ
        if benchmark:
            benchmark_data['frame_processing_times'].append(processing_time)
            benchmark_data['confidence_scores'].append(confidence)
            if len(tracker.bbox_history) >= 2:
                # ËÆ°ÁÆóbboxÁ®≥ÂÆöÊÄß
                prev_bbox = tracker.bbox_history[-2]
                curr_bbox = tracker.bbox_history[-1]
                stability = np.linalg.norm(np.array(curr_bbox[:2]) - np.array(prev_bbox[:2]))
                benchmark_data['bbox_stability'].append(stability)
        
        # ÂÜôÂÖ•ËæìÂá∫ËßÜÈ¢ë
        out.write(frame)
        
        # ÊòæÁ§∫ÁªìÊûúÔºàÂèØÈÄâÔºâ
        if display:
            cv2.imshow('LightTrack Improved', frame)
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                print("Áî®Êà∑‰∏≠Êñ≠Ë∑üË∏™")
                break
            elif key == ord(' '):  # Á©∫Ê†ºÈîÆÊöÇÂÅú
                cv2.waitKey(0)
        
        # ËØªÂèñ‰∏ã‰∏ÄÂ∏ß
        ret, frame = cap.read()
        frame_count += 1
        stats['total_frames'] = frame_count
        
        # ÊòæÁ§∫ËøõÂ∫¶
        if frame_count % 60 == 0:
            progress = (frame_count / total_frames) * 100
            elapsed = time.time() - stats['start_time']
            current_fps = frame_count / elapsed if elapsed > 0 else 0
            print(f"Â§ÑÁêÜËøõÂ∫¶: {progress:.1f}% ({frame_count}/{total_frames}) - "
                  f"Â§ÑÁêÜFPS: {current_fps:.1f}")
    
    # Ê∏ÖÁêÜËµÑÊ∫ê
    cap.release()
    out.release()
    if display:
        cv2.destroyAllWindows()
    
    # ËÆ°ÁÆóÊúÄÁªàÁªüËÆ°
    total_time = time.time() - stats['start_time']
    final_stats = tracker.get_stats()
    
    # ÊâìÂç∞ÁªìÊûú
    print_tracking_results(video_path, output_path, init_bbox, total_time, 
                          final_stats, stats, benchmark_data if benchmark else None)
    
    return output_path, final_stats


def print_tracking_results(input_path, output_path, init_bbox, total_time, 
                         tracker_stats, process_stats, benchmark_data=None):
    """ÊâìÂç∞Ë∑üË∏™ÁªìÊûú"""
    
    print("\n" + "="*60)
    print("üéâ Ë∑üË∏™ÂÆåÊàê!")
    print("="*60)
    print(f"üìÅ ËæìÂÖ•ËßÜÈ¢ë: {os.path.basename(input_path)}")
    print(f"üìÅ ËæìÂá∫ËßÜÈ¢ë: {os.path.basename(output_path)}")
    print(f"üéØ ÂàùÂßãÁõÆÊ†á: [{init_bbox[0]:.1f}, {init_bbox[1]:.1f}, {init_bbox[2]:.1f}, {init_bbox[3]:.1f}]")
    
    print(f"\nüìä Â§ÑÁêÜÁªüËÆ°:")
    print(f"   ÊÄªÂ§ÑÁêÜÊó∂Èó¥: {total_time:.2f}Áßí")
    print(f"   ÊÄªÂ∏ßÊï∞: {tracker_stats.get('total_frames', 0)}")
    print(f"   Â§ÑÁêÜÂ∏ßÊï∞: {tracker_stats.get('processed_frames', 0)}")
    print(f"   Ë∑≥ËøáÂ∏ßÊï∞: {tracker_stats.get('skipped_frames', 0)}")
    print(f"   ÊàêÂäüË∑üË∏™: {tracker_stats.get('successful_tracks', 0)}")
    
    print(f"\nüöÄ ÊÄßËÉΩÊåáÊ†á:")
    print(f"   Âπ≥ÂùáÂ§ÑÁêÜFPS: {tracker_stats.get('avg_fps', 0):.1f}")
    print(f"   Ë∑üË∏™ÊàêÂäüÁéá: {tracker_stats.get('success_rate', 0):.1f}%")
    
    if process_stats['processing_times']:
        avg_process_time = np.mean(process_stats['processing_times']) * 1000  # ÊØ´Áßí
        print(f"   Âπ≥ÂùáÂ∏ßÂ§ÑÁêÜÊó∂Èó¥: {avg_process_time:.1f}ms")
    
    # Ë∑≥Â∏ßÊïàÁéáÂàÜÊûê
    total_frames = tracker_stats.get('total_frames', 0)
    processed_frames = tracker_stats.get('processed_frames', 0)
    if total_frames > 0:
        skip_efficiency = (total_frames - processed_frames) / total_frames * 100
        print(f"   Ë∑≥Â∏ßÊïàÁéá: {skip_efficiency:.1f}%")
    
    # Âü∫ÂáÜÊµãËØïÁªìÊûú
    if benchmark_data:
        print(f"\nüß™ Âü∫ÂáÜÊµãËØï:")
        if benchmark_data['frame_processing_times']:
            avg_frame_time = np.mean(benchmark_data['frame_processing_times']) * 1000
            std_frame_time = np.std(benchmark_data['frame_processing_times']) * 1000
            print(f"   Â∏ßÂ§ÑÁêÜÊó∂Èó¥: {avg_frame_time:.1f}¬±{std_frame_time:.1f}ms")
        
        if benchmark_data['confidence_scores']:
            avg_confidence = np.mean(benchmark_data['confidence_scores'])
            print(f"   Âπ≥ÂùáÁΩÆ‰ø°Â∫¶: {avg_confidence:.3f}")
        
        if benchmark_data['bbox_stability']:
            avg_stability = np.mean(benchmark_data['bbox_stability'])
            print(f"   Ë∑üË∏™Á®≥ÂÆöÊÄß: {avg_stability:.1f}ÂÉèÁ¥†ÂÅèÁßª")
    
    # ÊÄßËÉΩÁ≠âÁ∫ßËØÑ‰º∞
    fps = tracker_stats.get('avg_fps', 0)
    success_rate = tracker_stats.get('success_rate', 0)
    
    if fps >= 60 and success_rate >= 90:
        grade = "üèÜ ‰ºòÁßÄ"
    elif fps >= 30 and success_rate >= 80:
        grade = "‚úÖ ËâØÂ•Ω"
    elif fps >= 15 and success_rate >= 60:
        grade = "‚ö†Ô∏è  ‰∏ÄËà¨"
    else:
        grade = "‚ùå ÈúÄË¶Å‰ºòÂåñ"
    
    print(f"\nüéñÔ∏è  ÊÄßËÉΩËØÑÁ∫ß: {grade}")


def run_benchmark_suite(video_path, init_bbox):
    """ËøêË°åÊÄßËÉΩÂü∫ÂáÜÊµãËØïÂ•ó‰ª∂"""
    print("\nüß™ ËøêË°åÊÄßËÉΩÂü∫ÂáÜÊµãËØïÂ•ó‰ª∂...")
    
    test_configs = [
        {'frame_skip': 1, 'target_fps': 30, 'name': 'Ê†áÂáÜÈÖçÁΩÆ'},
        {'frame_skip': 2, 'target_fps': 30, 'name': '2ÂÄçË∑≥Â∏ß'},
        {'frame_skip': 3, 'target_fps': 30, 'name': '3ÂÄçË∑≥Â∏ß'},
        {'frame_skip': 1, 'target_fps': 60, 'name': 'È´òFPS'},
        {'frame_skip': 2, 'target_fps': 60, 'name': 'È´òFPS+Ë∑≥Â∏ß'},
    ]
    
    results = []
    
    for config in test_configs:
        print(f"\nÊµãËØïÈÖçÁΩÆ: {config['name']}")
        try:
            output_path = f"benchmark_{config['name'].replace(' ', '_')}.mp4"
            _, stats = track_video_improved(
                video_path, init_bbox, output_path, 
                display=False, 
                frame_skip=config['frame_skip'],
                target_fps=config['target_fps'],
                benchmark=True
            )
            
            results.append({
                'config': config,
                'stats': stats,
                'output': output_path
            })
            
        except Exception as e:
            print(f"‚ùå ÊµãËØïÂ§±Ë¥•: {e}")
    
    # ÊâìÂç∞Âü∫ÂáÜÊµãËØïÊÄªÁªì
    print("\n" + "="*80)
    print("üèÜ Âü∫ÂáÜÊµãËØïÊÄªÁªì")
    print("="*80)
    print(f"{'ÈÖçÁΩÆ':<15} {'FPS':<10} {'ÊàêÂäüÁéá':<10} {'Â§ÑÁêÜÂ∏ß':<10} {'Ë∑≥Â∏ßÊïàÁéá':<10}")
    print("-" * 80)
    
    for result in results:
        config = result['config']
        stats = result['stats']
        
        fps = stats.get('avg_fps', 0)
        success_rate = stats.get('success_rate', 0)
        processed = stats.get('processed_frames', 0)
        total = stats.get('total_frames', 1)
        skip_eff = (total - processed) / total * 100
        
        print(f"{config['name']:<15} {fps:<10.1f} {success_rate:<10.1f}% "
              f"{processed:<10} {skip_eff:<10.1f}%")
    
    # Ê∏ÖÁêÜÂü∫ÂáÜÊµãËØïÊñá‰ª∂
    for result in results:
        try:
            os.remove(result['output'])
        except:
            pass


def main():
    """‰∏ªÂáΩÊï∞"""
    args = parse_args()
    
    # Ê£ÄÊü•ËßÜÈ¢ëÊñá‰ª∂
    if not os.path.exists(args.video):
        print(f"‚ùå ÈîôËØØ: ËßÜÈ¢ëÊñá‰ª∂‰∏çÂ≠òÂú®: {args.video}")
        return 1
    
    print("üöÄ LightTrack ÊîπËøõÁâàÂëΩ‰ª§Ë°åË∑üË∏™Â∑•ÂÖ∑")
    print("="*50)
    
    # Ëé∑ÂèñÂàùÂßãËæπÁïåÊ°Ü
    if args.bbox:
        try:
            init_bbox = parse_bbox(args.bbox)
        except ValueError as e:
            print(f"‚ùå ÈîôËØØ: {e}")
            return 1
    else:
        print("Êú™ÊåáÂÆöËæπÁïåÊ°ÜÔºåÂ∞ÜËøõÂÖ•‰∫§‰∫íÂºèÈÄâÊã©Ê®°Âºè")
        try:
            init_bbox = select_bbox_interactive(args.video)
            if init_bbox is None:
                print("Êú™ÈÄâÊã©ÁõÆÊ†áÔºåÈÄÄÂá∫Á®ãÂ∫è")
                return 1
        except Exception as e:
            print(f"‚ùå ÁõÆÊ†áÈÄâÊã©Â§±Ë¥•: {e}")
            return 1
    
    # ÂàÜÊûêËßÜÈ¢ëÂπ∂ÁªôÂá∫Âª∫ËÆÆ
    if args.auto_optimize:
        video_info, suggestions = analyze_video(args.video)
        if video_info and suggestions:
            print_video_analysis(video_info, suggestions)
            
            # Â∫îÁî®Âª∫ËÆÆ
            frame_skip = suggestions['frame_skip']
            target_fps = suggestions['target_fps']
            print(f"\nüîß Â∫îÁî®Ëá™Âä®‰ºòÂåñÂèÇÊï∞: Ë∑≥Â∏ß={frame_skip}, FPS={target_fps}")
        else:
            frame_skip = args.frame_skip
            target_fps = args.target_fps
    else:
        frame_skip = args.frame_skip
        target_fps = args.target_fps
    
    # Âü∫ÂáÜÊµãËØïÊ®°Âºè
    if args.benchmark:
        run_benchmark_suite(args.video, init_bbox)
        return 0
    
    # ÂºÄÂßãË∑üË∏™
    try:
        output_path, final_stats = track_video_improved(
            args.video, 
            init_bbox, 
            args.output, 
            args.display,
            frame_skip,
            target_fps,
            benchmark=False
        )
        
        print(f"\n‚úÖ Â§ÑÁêÜÂÆåÊàê! ËæìÂá∫Êñá‰ª∂: {output_path}")
        return 0
        
    except Exception as e:
        print(f"‚ùå Ë∑üË∏™Â§±Ë¥•: {e}")
        return 1


if __name__ == "__main__":
    exit(main())