#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¹³è¡¡é€Ÿåº¦ä¸å‡†ç¡®æ€§çš„æœ€ç»ˆè·Ÿè¸ªå™¨
Final Production Tracker - Balanced Speed and Accuracy
"""

import os
import sys
import cv2
import torch
import numpy as np
import time
from typing import Optional, Tuple, List

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

try:
    from tracking._init_paths import *
    import lib.models.models as models
    from lib.utils.utils import load_pretrain
    from lib.tracker.lighttrack import Lighttrack
    from easydict import EasyDict as edict
    LIGHTTRACK_AVAILABLE = True
except ImportError as e:
    print(f"LightTrackä¾èµ–å¯¼å…¥å¤±è´¥: {e}")
    LIGHTTRACK_AVAILABLE = False


class ProductionTracker:
    """ç”Ÿäº§çº§è·Ÿè¸ªå™¨ - å¹³è¡¡é€Ÿåº¦ä¸å‡†ç¡®æ€§"""
    
    def __init__(self, target_fps: float = 60.0):
        self.model = None
        self.tracker = None
        self.device = 'cpu'
        self.initialized = False
        self.last_bbox = None
        self.template = None
        self.target_fps = target_fps  # ç›®æ ‡FPSï¼Œå¹³è¡¡é€Ÿåº¦ä¸å‡†ç¡®æ€§
        
        # è·Ÿè¸ªå†å²ç”¨äºç¨³å®šæ€§
        self.bbox_history = []
        self.confidence_history = []
        self.max_history = 5
        
        # æ€§èƒ½ç»Ÿè®¡
        self.frame_times = []
        self.success_count = 0
        self.total_frames = 0
        
        # åŠ è½½æ¨¡å‹
        self._load_model()
    
    def _load_model(self) -> bool:
        """åŠ è½½LightTrackæ¨¡å‹"""
        if not LIGHTTRACK_AVAILABLE:
            print("âš ï¸  ä½¿ç”¨é«˜é€Ÿæ¼”ç¤ºæ¨¡å¼")
            return False
        
        try:
            # æ£€æŸ¥CUDA
            if torch.cuda.is_available():
                self.device = 'cuda'
                print("âœ… ä½¿ç”¨GPUåŠ é€Ÿ")
            else:
                self.device = 'cpu'
                print("ğŸ’» ä½¿ç”¨CPUè®¡ç®—")
            
            # æ¨¡å‹é…ç½®
            info = edict()
            info.arch = 'LightTrackM_Speed'
            info.dataset = 'VOT2019'
            info.stride = 16
            
            # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
            model_paths = [
                os.path.join(current_dir, 'snapshot', 'LightTrackM', 'LightTrackM.pth'),
                os.path.join(current_dir, 'snapshot', 'checkpoint_e30.pth')
            ]
            
            model_path = None
            for path in model_paths:
                if os.path.exists(path):
                    model_path = path
                    break
            
            if not model_path:
                print("âš ï¸  æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œä½¿ç”¨æ¼”ç¤ºæ¨¡å¼")
                return False
            
            # åˆ›å»ºè·Ÿè¸ªå™¨
            self.tracker = Lighttrack(info)
            
            # åˆ›å»ºæ¨¡å‹
            try:
                model = models.LightTrackM_Speed(
                    path_name='back_04502514044521042540+cls_211000022+reg_100000111_ops_32'
                )
            except TypeError:
                model = models.LightTrackM_Subnet(
                    path_name='back_04502514044521042540+cls_211000022+reg_100000111_ops_32',
                    stride=info.stride
                )
            
            model = model.to(self.device)
            model.eval()
            
            # åŠ è½½é¢„è®­ç»ƒæƒé‡
            print(f"ğŸ“¥ åŠ è½½æ¨¡å‹: {os.path.basename(model_path)}")
            model = load_pretrain(model, model_path, print_unuse=False)
            
            self.model = model
            print("âœ… çœŸå®LightTrackæ¨¡å‹åŠ è½½æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âš ï¸  æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨æ¼”ç¤ºæ¨¡å¼: {e}")
            self.model = None
            self.tracker = None
            return False
    
    def initialize(self, frame: np.ndarray, bbox: List[float]) -> bool:
        """åˆå§‹åŒ–è·Ÿè¸ªå™¨"""
        self.last_bbox = bbox.copy()
        
        # æ¸…ç©ºå†å²
        self.bbox_history = [bbox.copy()]
        self.confidence_history = [1.0]
        
        if self.model is not None and self.tracker is not None:
            return self._initialize_real_tracker(frame, bbox)
        else:
            return self._initialize_demo_tracker(frame, bbox)
    
    def _initialize_real_tracker(self, frame: np.ndarray, bbox: List[float]) -> bool:
        """åˆå§‹åŒ–çœŸå®LightTrackè·Ÿè¸ªå™¨"""
        try:
            x, y, w, h = bbox
            cx, cy = x + w/2, y + h/2
            
            # åˆå§‹åŒ–è·Ÿè¸ªå™¨
            self.tracker.init(frame, [cx, cy, w, h])
            self.initialized = True
            
            print("âœ… çœŸå®LightTrackè·Ÿè¸ªå™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ çœŸå®è·Ÿè¸ªå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return self._initialize_demo_tracker(frame, bbox)
    
    def _initialize_demo_tracker(self, frame: np.ndarray, bbox: List[float]) -> bool:
        """åˆå§‹åŒ–æ¼”ç¤ºè·Ÿè¸ªå™¨"""
        try:
            x, y, w, h = [int(v) for v in bbox]
            
            # è¾¹ç•Œæ£€æŸ¥
            if (x < 0 or y < 0 or x + w > frame.shape[1] or 
                y + h > frame.shape[0] or w <= 0 or h <= 0):
                print(f"âŒ æ— æ•ˆè¾¹ç•Œæ¡†: {bbox}")
                return False
            
            # æå–æ¨¡æ¿
            template_region = frame[y:y+h, x:x+w]
            if template_region.size == 0:
                return False
            
            # ä½¿ç”¨åˆé€‚çš„æ¨¡æ¿å¤§å°
            template_size = min(127, max(w, h))
            self.template = cv2.resize(template_region, (template_size, template_size))
            
            self.initialized = True
            print("âœ… æ¼”ç¤ºè·Ÿè¸ªå™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ æ¼”ç¤ºè·Ÿè¸ªå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def track(self, frame: np.ndarray) -> Tuple[bool, List[float], float]:
        """æ‰§è¡Œè·Ÿè¸ª"""
        start_time = time.time()
        
        if not self.initialized:
            return False, self.last_bbox, 0.0
        
        try:
            if self.model is not None and self.tracker is not None:
                # ä½¿ç”¨çœŸå®LightTrackæ¨¡å‹
                success, bbox, confidence = self._track_real(frame)
            else:
                # ä½¿ç”¨é«˜è´¨é‡æ¼”ç¤ºæ¨¡å¼
                success, bbox, confidence = self._track_demo_balanced(frame)
            
            # æ›´æ–°ç»Ÿè®¡
            self.total_frames += 1
            if success:
                self.success_count += 1
            
            # æ›´æ–°å†å²
            self._update_history(bbox, confidence)
            
            # æ ¹æ®ç›®æ ‡FPSè°ƒæ•´å¤„ç†é€Ÿåº¦
            elapsed = time.time() - start_time
            target_time = 1.0 / self.target_fps
            if elapsed < target_time:
                time.sleep(target_time - elapsed)
            
            self.frame_times.append(time.time() - start_time)
            if len(self.frame_times) > 100:
                self.frame_times = self.frame_times[-100:]
            
            return success, bbox, confidence
            
        except Exception as e:
            print(f"âŒ è·Ÿè¸ªå¤±è´¥: {e}")
            return False, self.last_bbox, 0.0
    
    def _track_real(self, frame: np.ndarray) -> Tuple[bool, List[float], float]:
        """ä½¿ç”¨çœŸå®LightTrackæ¨¡å‹è·Ÿè¸ª"""
        try:
            bbox = self.tracker.update(frame)
            
            if bbox is not None and len(bbox) >= 4:
                cx, cy, w, h = bbox[:4]
                x = cx - w/2
                y = cy - h/2
                
                new_bbox = [x, y, w, h]
                
                # è¾¹ç•Œæ£€æŸ¥
                h_frame, w_frame = frame.shape[:2]
                if (x >= 0 and y >= 0 and x + w <= w_frame and 
                    y + h <= h_frame and w > 10 and h > 10):
                    
                    self.last_bbox = new_bbox
                    return True, new_bbox, 0.9
            
            return False, self.last_bbox, 0.1
            
        except Exception as e:
            print(f"âŒ çœŸå®è·Ÿè¸ªå¤±è´¥: {e}")
            return self._track_demo_balanced(frame)
    
    def _track_demo_balanced(self, frame: np.ndarray) -> Tuple[bool, List[float], float]:
        """å¹³è¡¡çš„æ¼”ç¤ºæ¨¡å¼è·Ÿè¸ª"""
        if self.template is None:
            return False, self.last_bbox, 0.0
        
        try:
            x, y, w, h = [int(v) for v in self.last_bbox]
            h_frame, w_frame = frame.shape[:2]
            
            # æ™ºèƒ½æœç´¢åŒºåŸŸå¤§å°
            movement_scale = max(0.5, min(2.0, self.target_fps / 30.0))
            search_margin = int(max(20, (w + h) * 0.25 * movement_scale))
            
            search_x1 = max(0, x - search_margin)
            search_y1 = max(0, y - search_margin)
            search_x2 = min(w_frame, x + w + search_margin)
            search_y2 = min(h_frame, y + h + search_margin)
            
            search_region = frame[search_y1:search_y2, search_x1:search_x2]
            
            # æ£€æŸ¥æœç´¢åŒºåŸŸ
            if (search_region.shape[0] < self.template.shape[0] or 
                search_region.shape[1] < self.template.shape[1]):
                return False, self.last_bbox, 0.1
            
            # å¤šå°ºåº¦æ¨¡æ¿åŒ¹é…ä»¥æé«˜å‡†ç¡®æ€§
            best_val = 0
            best_loc = None
            best_scale = 1.0
            
            scales = [0.9, 1.0, 1.1] if self.target_fps > 30 else [1.0]
            
            for scale in scales:
                try:
                    if scale != 1.0:
                        scaled_template = cv2.resize(
                            self.template, 
                            (int(self.template.shape[1] * scale),
                             int(self.template.shape[0] * scale))
                        )
                    else:
                        scaled_template = self.template
                    
                    if (scaled_template.shape[0] <= search_region.shape[0] and 
                        scaled_template.shape[1] <= search_region.shape[1]):
                        
                        result = cv2.matchTemplate(search_region, scaled_template, 
                                                 cv2.TM_CCOEFF_NORMED)
                        _, max_val, _, max_loc = cv2.minMaxLoc(result)
                        
                        if max_val > best_val:
                            best_val = max_val
                            best_loc = max_loc
                            best_scale = scale
                    
                except:
                    continue
            
            # æ™ºèƒ½é˜ˆå€¼è°ƒæ•´
            confidence_threshold = max(0.4, 0.7 - (self.target_fps - 30) * 0.01)
            
            if best_val > confidence_threshold and best_loc is not None:
                match_x, match_y = best_loc
                
                new_x = search_x1 + match_x
                new_y = search_y1 + match_y
                new_w = int(w * best_scale)
                new_h = int(h * best_scale)
                
                # è¾¹ç•Œæ£€æŸ¥
                new_x = max(0, min(w_frame - new_w, new_x))
                new_y = max(0, min(h_frame - new_h, new_y))
                
                new_bbox = [new_x, new_y, new_w, new_h]
                
                # æ¨¡æ¿æ›´æ–°ç­–ç•¥
                if best_val > 0.7 and len(self.confidence_history) > 0:
                    avg_confidence = np.mean(self.confidence_history[-3:])
                    if avg_confidence > 0.6:  # åªæœ‰æŒç»­é«˜ç½®ä¿¡åº¦æ‰æ›´æ–°æ¨¡æ¿
                        self._update_template(frame, new_bbox, best_val)
                
                self.last_bbox = new_bbox
                return True, new_bbox, best_val
            else:
                # ä½¿ç”¨å†å²ä¿¡æ¯é¢„æµ‹ä½ç½®
                predicted_bbox = self._predict_bbox()
                return False, predicted_bbox, best_val
                
        except Exception as e:
            print(f"âŒ æ¼”ç¤ºè·Ÿè¸ªå¤±è´¥: {e}")
            return False, self.last_bbox, 0.0
    
    def _update_template(self, frame: np.ndarray, bbox: List[float], confidence: float):
        """æ™ºèƒ½æ¨¡æ¿æ›´æ–°"""
        try:
            x, y, w, h = [int(v) for v in bbox]
            
            if (x >= 0 and y >= 0 and x + w <= frame.shape[1] and 
                y + h <= frame.shape[0] and w > 0 and h > 0):
                
                new_template_region = frame[y:y+h, x:x+w]
                if new_template_region.size > 0:
                    # è°ƒæ•´åˆ°ç›¸åŒå¤§å°
                    new_template = cv2.resize(new_template_region, 
                                            (self.template.shape[1], self.template.shape[0]))
                    
                    # è‡ªé€‚åº”å­¦ä¹ ç‡
                    learning_rate = min(0.1, confidence * 0.15)
                    
                    # åŠ æƒæ›´æ–°
                    self.template = cv2.addWeighted(
                        self.template.astype(np.float32), 1 - learning_rate,
                        new_template.astype(np.float32), learning_rate, 0
                    ).astype(np.uint8)
        except:
            pass  # æ¨¡æ¿æ›´æ–°å¤±è´¥ä¸å½±å“è·Ÿè¸ª
    
    def _update_history(self, bbox: List[float], confidence: float):
        """æ›´æ–°è·Ÿè¸ªå†å²"""
        self.bbox_history.append(bbox.copy())
        self.confidence_history.append(confidence)
        
        if len(self.bbox_history) > self.max_history:
            self.bbox_history = self.bbox_history[-self.max_history:]
            self.confidence_history = self.confidence_history[-self.max_history:]
    
    def _predict_bbox(self) -> List[float]:
        """åŸºäºå†å²é¢„æµ‹è¾¹ç•Œæ¡†"""
        if len(self.bbox_history) < 2:
            return self.last_bbox.copy()
        
        # ç®€å•çš„è¿åŠ¨é¢„æµ‹
        try:
            last_bbox = self.bbox_history[-1]
            prev_bbox = self.bbox_history[-2]
            
            dx = last_bbox[0] - prev_bbox[0]
            dy = last_bbox[1] - prev_bbox[1]
            
            # é™åˆ¶è¿åŠ¨å¹…åº¦
            dx = max(-20, min(20, dx))
            dy = max(-20, min(20, dy))
            
            predicted_x = last_bbox[0] + dx
            predicted_y = last_bbox[1] + dy
            
            return [predicted_x, predicted_y, last_bbox[2], last_bbox[3]]
        except:
            return self.last_bbox.copy()
    
    def get_stats(self) -> dict:
        """è·å–è·Ÿè¸ªç»Ÿè®¡ä¿¡æ¯"""
        fps = 1.0 / np.mean(self.frame_times) if self.frame_times else 0.0
        success_rate = (self.success_count / self.total_frames * 100) if self.total_frames > 0 else 0.0
        
        return {
            'fps': fps,
            'success_rate': success_rate,
            'total_frames': self.total_frames,
            'successful_frames': self.success_count,
            'model_type': 'LightTrack' if self.model else 'Balanced Demo',
            'device': self.device,
            'target_fps': self.target_fps
        }


def test_production_tracker():
    """æµ‹è¯•ç”Ÿäº§çº§è·Ÿè¸ªå™¨"""
    print("ğŸ­ ç”Ÿäº§çº§è·Ÿè¸ªå™¨æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•ä¸åŒFPSç›®æ ‡
    fps_targets = [30, 60, 90]
    
    for target_fps in fps_targets:
        print(f"\nğŸ¯ æµ‹è¯•ç›®æ ‡FPS: {target_fps}")
        print("-" * 30)
        
        tracker = ProductionTracker(target_fps=target_fps)
        
        # æµ‹è¯•è§†é¢‘
        cap = cv2.VideoCapture('sample_video.mp4')
        ret, frame = cap.read()
        if not ret:
            print("âŒ æ— æ³•è¯»å–è§†é¢‘")
            continue
        
        # åˆå§‹åŒ–
        bbox = [390, 210, 60, 60]
        success = tracker.initialize(frame, bbox)
        
        if not success:
            print("âŒ åˆå§‹åŒ–å¤±è´¥")
            continue
        
        # æµ‹è¯•30å¸§
        test_frames = 30
        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
        
        start_time = time.time()
        
        for i in range(test_frames):
            ret, frame = cap.read()
            if not ret:
                break
            
            success, bbox, confidence = tracker.track(frame)
        
        total_time = time.time() - start_time
        cap.release()
        
        # æ˜¾ç¤ºç»“æœ
        stats = tracker.get_stats()
        print(f"   å®é™…FPS: {stats['fps']:.1f}")
        print(f"   æˆåŠŸç‡: {stats['success_rate']:.1f}%")
        print(f"   æ€»æ—¶é—´: {total_time:.3f}ç§’")
        print(f"   è·Ÿè¸ªå™¨ç±»å‹: {stats['model_type']}")


if __name__ == '__main__':
    test_production_tracker()