# LightTrack: è½»é‡çº§ç›®æ ‡è·Ÿè¸ªç¥ç»ç½‘ç»œ

<div align="center">
  <img src="Archs.gif" width="800px" />
</div>

## é¡¹ç›®ç®€ä»‹

LightTrackæ˜¯ä¸€ä¸ªåŸºäºç¥ç»æ¶æ„æœç´¢(NAS)çš„è½»é‡çº§ç›®æ ‡è·Ÿè¸ªç³»ç»Ÿã€‚è¯¥é¡¹ç›®é€šè¿‡è‡ªåŠ¨åŒ–çš„æ¶æ„æœç´¢æŠ€æœ¯ï¼Œè®¾è®¡å‡ºæ›´åŠ è½»é‡ä¸”é«˜æ•ˆçš„ç›®æ ‡è·Ÿè¸ªå™¨ã€‚

### ä¸»è¦ç‰¹ç‚¹

- ğŸš€ **é«˜æ•ˆè½»é‡**ï¼šç›¸æ¯”ä¼ ç»ŸSOTAè·Ÿè¸ªå™¨ï¼ˆå¦‚SiamRPN++å’ŒOceanï¼‰ï¼Œä½¿ç”¨æ›´å°‘çš„æ¨¡å‹å‚æ•°å’Œè®¡ç®—é‡
- ğŸ“± **ç§»åŠ¨ç«¯ä¼˜åŒ–**ï¼šåœ¨Snapdragon 845 Adreno GPUä¸Šè¿è¡Œé€Ÿåº¦æ¯”Oceanå¿«12å€
- ğŸ¯ **ç²¾å‡†è·Ÿè¸ª**ï¼šåœ¨ä¿æŒè½»é‡åŒ–çš„åŒæ—¶å®ç°ä¼˜ç§€çš„è·Ÿè¸ªæ€§èƒ½
- ğŸ”§ **æ˜“äºéƒ¨ç½²**ï¼šç¼©å°å­¦æœ¯æ¨¡å‹ä¸å·¥ä¸šéƒ¨ç½²ä¹‹é—´çš„å·®è·

<div align="center">
  <img src="LightTrack_Fig1.PNG" width="500px" />
</div>

## æŠ€æœ¯æ¶æ„

### æ ¸å¿ƒç»„ä»¶

1. **è¶…ç½‘ç»œè®¾è®¡** - ä½¿ç”¨ç¥ç»æ¶æ„æœç´¢æ„å»ºçš„é«˜æ•ˆç½‘ç»œæ¶æ„
2. **è½»é‡çº§è·Ÿè¸ªå™¨** - åŸºäºSiameseç½‘ç»œçš„ç›®æ ‡è·Ÿè¸ªç®—æ³•
3. **å¤šå°ºåº¦æœç´¢** - æ”¯æŒä¸åŒå°ºåº¦çš„ç›®æ ‡æ£€æµ‹å’Œè·Ÿè¸ª
4. **å®æ—¶å¤„ç†** - ä¼˜åŒ–çš„æ¨ç†é€Ÿåº¦ï¼Œé€‚åˆå®æ—¶åº”ç”¨

### ç½‘ç»œç»“æ„

- **éª¨å¹²ç½‘ç»œ**: EfficientNet-basedè¶…ç½‘ç»œ
- **ç‰¹å¾æå–**: è½»é‡çº§å·ç§¯ç‰¹å¾æå–å™¨
- **ç›¸ä¼¼åº¦è®¡ç®—**: Siameseç½‘ç»œæ¶æ„
- **è¾¹ç•Œæ¡†å›å½’**: ç²¾ç¡®çš„ç›®æ ‡å®šä½

## ç¯å¢ƒé…ç½®

### ç³»ç»Ÿè¦æ±‚

- Python 3.6+
- CUDA 10.0+
- PyTorch 1.1.0+
- OpenCV 4.0+

### å®‰è£…æ­¥éª¤

1. **å…‹éš†é¡¹ç›®**
```bash
git clone https://github.com/git-xiaomy/LightTrack.git
cd LightTrack
```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**
```bash
conda create -n lighttrack python=3.6
conda activate lighttrack
```

3. **å®‰è£…ä¾èµ–**
```bash
bash install.sh
```

### æ‰‹åŠ¨å®‰è£…ä¾èµ–

å¦‚æœè‡ªåŠ¨å®‰è£…è„šæœ¬å¤±è´¥ï¼Œå¯ä»¥æ‰‹åŠ¨å®‰è£…ä»¥ä¸‹ä¾èµ–ï¼š

```bash
# åŸºç¡€ä¾èµ–
pip install torch==1.1.0 torchvision==0.3.0
pip install opencv-python
pip install numpy pandas scipy
pip install pillow scikit-image
pip install easydict pyyaml

# ä¸“ç”¨ä¾èµ–
pip install lmdb jpeg4py
pip install cython==0.29.21
pip install shapely numba
pip install yacs timm==0.1.20
pip install tensorboardX colorama

# è®¡ç®—FLOPså·¥å…·
pip install --upgrade git+https://github.com/Lyken17/pytorch-OpCounter.git
```

## æ•°æ®å‡†å¤‡

### è·Ÿè¸ªæ•°æ®é›†

æ”¯æŒçš„æ•°æ®é›†æ ¼å¼ï¼š
- VOT2019
- OTB2015
- LaSOT
- GOT-10K

### æ•°æ®ç›®å½•ç»“æ„

```
LightTrack/
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ VOT2019.json
â”‚   â”œâ”€â”€ VOT2019/
â”‚   â”‚   â”œâ”€â”€ agility/
â”‚   â”‚   â”œâ”€â”€ ants1/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ list.txt
â”œâ”€â”€ snapshot/          # é¢„è®­ç»ƒæ¨¡å‹
â”œâ”€â”€ experiments/       # é…ç½®æ–‡ä»¶
â””â”€â”€ tracking/         # è·Ÿè¸ªè„šæœ¬
```

## æ¨¡å‹ä½¿ç”¨

### é¢„è®­ç»ƒæ¨¡å‹

é¡¹ç›®æä¾›é¢„è®­ç»ƒçš„è¶…ç½‘ç»œæƒé‡ï¼š
- ImageNetåˆ†ç±»é¢„è®­ç»ƒæ¨¡å‹
- ç›®æ ‡è·Ÿè¸ªé¢„è®­ç»ƒæ¨¡å‹

ä¸‹è½½é“¾æ¥ï¼š[Google Drive](https://drive.google.com/drive/folders/1HXhdJO3yhQYw3O7nGUOXHu2S20Bs8CfI)

### åŸºæœ¬ä½¿ç”¨æ–¹æ³•

#### 1. æµ‹è¯•å•ä¸ªè§†é¢‘

```bash
cd tracking
python test_lighttrack.py \
    --arch LightTrackM_Subnet \
    --resume ../snapshot/LightTrack_M.pth \
    --video your_video_name
```

#### 2. æ‰¹é‡æµ‹è¯•

```bash
bash reproduce_vot2019.sh
```

#### 3. æ€§èƒ½è¯„ä¼°

```bash
# è®¡ç®—FLOPså’Œå‚æ•°é‡
python FLOPs_Params.py

# æµ‹è¯•è¿è¡Œé€Ÿåº¦
python Speed.py
```

## MP4è§†é¢‘è·Ÿè¸ªæ•™ç¨‹

### å‡†å¤‡å·¥ä½œ

1. **å‡†å¤‡MP4è§†é¢‘æ–‡ä»¶**
2. **è½¬æ¢è§†é¢‘æ ¼å¼**ï¼ˆå¦‚æœéœ€è¦ï¼‰
3. **æå–è§†é¢‘å¸§**

### è¯¦ç»†æ­¥éª¤

#### æ­¥éª¤1ï¼šè§†é¢‘é¢„å¤„ç†

```python
import cv2
import os

def extract_frames(video_path, output_dir):
    """ä»MP4è§†é¢‘æå–å¸§"""
    cap = cv2.VideoCapture(video_path)
    frame_count = 0
    
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_path = os.path.join(output_dir, f"{frame_count:06d}.jpg")
        cv2.imwrite(frame_path, frame)
        frame_count += 1
    
    cap.release()
    return frame_count

# ä½¿ç”¨ç¤ºä¾‹
video_path = "your_video.mp4"
output_dir = "video_frames"
total_frames = extract_frames(video_path, output_dir)
```

#### æ­¥éª¤2ï¼šåˆå§‹åŒ–è·Ÿè¸ªå™¨

```python
import sys
sys.path.append('.')
from tracking.test_lighttrack import *

# é…ç½®å‚æ•°
args = type('Args', (), {
    'arch': 'LightTrackM_Subnet',
    'resume': 'snapshot/LightTrack_M.pth',
    'dataset': 'VOT2019',
    'stride': 16
})()

# åˆå§‹åŒ–è·Ÿè¸ªå™¨
info = edict()
info.arch = args.arch
info.dataset = args.dataset
info.stride = args.stride

tracker = Lighttrack(info)
```

#### æ­¥éª¤3ï¼šç›®æ ‡åˆå§‹åŒ–å’Œè·Ÿè¸ª

```python
def track_video(tracker, model, frames_dir, init_bbox):
    """
    è·Ÿè¸ªè§†é¢‘ä¸­çš„ç›®æ ‡
    
    Args:
        tracker: LightTrackè·Ÿè¸ªå™¨
        model: åŠ è½½çš„æ¨¡å‹
        frames_dir: è§†é¢‘å¸§ç›®å½•
        init_bbox: åˆå§‹è¾¹ç•Œæ¡† [x, y, w, h]
    """
    frame_files = sorted(os.listdir(frames_dir))
    results = []
    
    for i, frame_file in enumerate(frame_files):
        frame_path = os.path.join(frames_dir, frame_file)
        frame = cv2.imread(frame_path)
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        if i == 0:  # åˆå§‹åŒ–
            cx = init_bbox[0] + init_bbox[2] / 2
            cy = init_bbox[1] + init_bbox[3] / 2
            target_pos = np.array([cx, cy])
            target_sz = np.array([init_bbox[2], init_bbox[3]])
            
            state = tracker.init(rgb_frame, target_pos, target_sz, model)
            results.append(init_bbox)
        else:  # è·Ÿè¸ª
            state = tracker.track(state, rgb_frame)
            
            # è½¬æ¢ç»“æœæ ¼å¼
            cx, cy = state['target_pos']
            w, h = state['target_sz']
            bbox = [cx - w/2, cy - h/2, w, h]
            results.append(bbox)
    
    return results
```

### å¯è§†åŒ–ç»“æœ

```python
def visualize_tracking(frames_dir, results, output_video):
    """å¯è§†åŒ–è·Ÿè¸ªç»“æœ"""
    frame_files = sorted(os.listdir(frames_dir))
    
    # è·å–è§†é¢‘å‚æ•°
    first_frame = cv2.imread(os.path.join(frames_dir, frame_files[0]))
    height, width = first_frame.shape[:2]
    
    # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video, fourcc, 30.0, (width, height))
    
    for i, (frame_file, bbox) in enumerate(zip(frame_files, results)):
        frame_path = os.path.join(frames_dir, frame_file)
        frame = cv2.imread(frame_path)
        
        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        x, y, w, h = [int(v) for v in bbox]
        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
        
        # æ·»åŠ å¸§å·
        cv2.putText(frame, f'Frame: {i+1}', (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        
        out.write(frame)
    
    out.release()
    print(f"è·Ÿè¸ªç»“æœå·²ä¿å­˜åˆ°: {output_video}")
```

## GUIç•Œé¢åº”ç”¨

é¡¹ç›®æä¾›äº†ä¸€ä¸ªå›¾å½¢ç”¨æˆ·ç•Œé¢ï¼Œæ–¹ä¾¿ç”¨æˆ·é€‰æ‹©è§†é¢‘æ–‡ä»¶å¹¶è¿›è¡Œç›®æ ‡è·Ÿè¸ªã€‚

### åŠŸèƒ½ç‰¹ç‚¹

- ğŸ“ **æ–‡ä»¶é€‰æ‹©**ï¼šæ”¯æŒé€‰æ‹©MP4ã€AVIç­‰å¸¸è§è§†é¢‘æ ¼å¼
- ğŸ¯ **ç›®æ ‡æ¡†é€‰**ï¼šåœ¨ç¬¬ä¸€å¸§ä¸­æ‰‹åŠ¨æ¡†é€‰è¦è·Ÿè¸ªçš„ç›®æ ‡
- â–¶ï¸ **å®æ—¶è·Ÿè¸ª**ï¼šæ˜¾ç¤ºè·Ÿè¸ªè¿‡ç¨‹å’Œç»“æœ
- ğŸ’¾ **ç»“æœä¿å­˜**ï¼šä¿å­˜è·Ÿè¸ªç»“æœè§†é¢‘

### ä½¿ç”¨æ–¹æ³•

```bash
python gui_tracker.py
```

ç•Œé¢æ“ä½œæ­¥éª¤ï¼š
1. ç‚¹å‡»"é€‰æ‹©è§†é¢‘"æŒ‰é’®é€‰æ‹©MP4æ–‡ä»¶
2. åœ¨å¼¹å‡ºçš„ç¬¬ä¸€å¸§å›¾åƒä¸­æ‹–æ‹½é¼ æ ‡æ¡†é€‰ç›®æ ‡
3. ç‚¹å‡»"å¼€å§‹è·Ÿè¸ª"æŒ‰é’®å¼€å§‹è‡ªåŠ¨è·Ÿè¸ª
4. è·Ÿè¸ªå®Œæˆåå¯é€‰æ‹©ä¿å­˜ç»“æœ

## æ€§èƒ½æŒ‡æ ‡

### æ¨¡å‹å¯¹æ¯”

| æ¨¡å‹ | å‚æ•°é‡ | FLOPs | VOT2019 EAO | é€Ÿåº¦(fps) |
|------|--------|-------|-------------|-----------|
| SiamRPN++ | 53.8M | 15.3G | 0.285 | 35 |
| Ocean | 32.7M | 17.6G | 0.289 | 25 |
| **LightTrack-Mobile** | **2.5M** | **0.46G** | **0.324** | **300** |

### ç§»åŠ¨ç«¯æ€§èƒ½

åœ¨Snapdragon 845 Adreno GPUä¸Šçš„æµ‹è¯•ç»“æœï¼š
- **é€Ÿåº¦æå‡**: æ¯”Oceanå¿«12å€
- **å‚æ•°å‡å°‘**: æ¯”Oceanå°‘13å€å‚æ•°
- **è®¡ç®—é‡å‡å°‘**: æ¯”Oceanå°‘38å€FLOPs

## å¸¸è§é—®é¢˜è§£ç­”

### Q1: å¦‚ä½•å¤„ç†ä¸åŒåˆ†è¾¨ç‡çš„è§†é¢‘ï¼Ÿ

A1: LightTrackä¼šè‡ªåŠ¨é€‚é…ä¸åŒåˆ†è¾¨ç‡ã€‚å¯¹äºé«˜åˆ†è¾¨ç‡è§†é¢‘ï¼Œå»ºè®®å…ˆç¼©æ”¾åˆ°åˆé€‚å°ºå¯¸ä»¥æé«˜å¤„ç†é€Ÿåº¦ã€‚

### Q2: è·Ÿè¸ªæ•ˆæœä¸ç†æƒ³æ€ä¹ˆåŠï¼Ÿ

A2: å¯ä»¥å°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š
- è°ƒæ•´åˆå§‹è¾¹ç•Œæ¡†çš„ç²¾åº¦
- é€‰æ‹©æ›´æ¸…æ™°çš„åˆå§‹å¸§
- è°ƒæ•´è·Ÿè¸ªå‚æ•°ï¼ˆåœ¨é…ç½®æ–‡ä»¶ä¸­ï¼‰

### Q3: å¦‚ä½•åœ¨CPUä¸Šè¿è¡Œï¼Ÿ

A3: ä¿®æ”¹ä»£ç ä¸­çš„`.cuda()`è°ƒç”¨ï¼Œæ”¹ä¸º`.cpu()`å³å¯åœ¨CPUä¸Šè¿è¡Œã€‚

### Q4: æ”¯æŒå¤šç›®æ ‡è·Ÿè¸ªå—ï¼Ÿ

A4: å½“å‰ç‰ˆæœ¬ä¸»è¦æ”¯æŒå•ç›®æ ‡è·Ÿè¸ªã€‚å¤šç›®æ ‡è·Ÿè¸ªéœ€è¦é¢å¤–çš„å®ç°ã€‚

## é¡¹ç›®ç»“æ„è¯¦è§£

```
LightTrack/
â”œâ”€â”€ lib/                    # æ ¸å¿ƒåº“
â”‚   â”œâ”€â”€ models/            # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ tracker/           # è·Ÿè¸ªç®—æ³•
â”‚   â”œâ”€â”€ utils/             # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ eval_toolkit/      # è¯„ä¼°å·¥å…·
â”œâ”€â”€ tracking/              # è·Ÿè¸ªè„šæœ¬
â”‚   â”œâ”€â”€ test_lighttrack.py # æµ‹è¯•è„šæœ¬
â”‚   â”œâ”€â”€ Speed.py           # é€Ÿåº¦æµ‹è¯•
â”‚   â””â”€â”€ FLOPs_Params.py    # æ€§èƒ½æµ‹è¯•
â”œâ”€â”€ experiments/           # å®éªŒé…ç½®
â”œâ”€â”€ dataset/              # æ•°æ®é›†
â”œâ”€â”€ snapshot/             # æ¨¡å‹æƒé‡
â””â”€â”€ gui_tracker.py        # GUIåº”ç”¨ï¼ˆæ–°å¢ï¼‰
```

## è®ºæ–‡å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†LightTrackï¼Œè¯·å¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š

```bibtex
@article{yan2021lighttrack,
  title={LightTrack: Finding Lightweight Neural Networks for Object Tracking via One-Shot Architecture Search},
  author={Yan, Bin and Peng, Houwen and Wu, Kan and Wang, Dong and Fu, Jianlong and Lu, Huchuan},
  journal={arXiv preprint arXiv:2104.14545},
  year={2021}
}
```

## è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäºMITè®¸å¯è¯å¼€æºã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›é¡¹ç›®ã€‚åœ¨æäº¤ä»£ç å‰è¯·ç¡®ä¿ï¼š

1. ä»£ç ç¬¦åˆé¡¹ç›®é£æ ¼
2. æ·»åŠ å¿…è¦çš„æ³¨é‡Š
3. é€šè¿‡æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹

## è”ç³»æ–¹å¼

- é¡¹ç›®ç»´æŠ¤è€…ï¼šhouwen.peng@microsoft.com
- é—®é¢˜åé¦ˆï¼šé€šè¿‡GitHub Issues

---

**æ³¨æ„**ï¼šæœ¬é¡¹ç›®ä»…ç”¨äºå­¦æœ¯ç ”ç©¶ã€‚å•†ä¸šä½¿ç”¨è¯·è”ç³»é¡¹ç›®ä½œè€…è·å¾—æˆæƒã€‚