# LightTrack: Finding Lightweight Neural Networks for Object Tracking via One-Shot Architecture Search

<div align="center">
  <img src="Archs.gif" width="800px" />
</div>

The official implementation of the paper 

[**LightTrack: Finding Lightweight Neural Networks for Object Tracking via One-Shot Architecture Search**](https://arxiv.org/abs/2104.14545)

Hiring research interns for visual transformer projects: houwen.peng@microsoft.com
## News
- We have uploaded the **pre-trained weights of the SuperNets**(for both ImageNet classification and object tracking) to [Google Drive](https://drive.google.com/drive/folders/1HXhdJO3yhQYw3O7nGUOXHu2S20Bs8CfI). Users can use them as initialization for future research on **efficient object tracking**.
## Abstract

We present LightTrack, which uses neural architecture search (NAS) to design more lightweight and efficient object trackers. Comprehensive experiments show that our LightTrack is effective. It can find trackers that achieve superior performance compared to handcrafted SOTA trackers, such as SiamRPN++ and Ocean, while using much fewer model Flops and parameters. Moreover, when deployed on resource-constrained mobile chipsets, the discovered trackers run much faster. For example, on Snapdragon 845 Adreno GPU, LightTrack runs 12Ã— faster than Ocean, while using 13Ã— fewer parameters and 38Ã— fewer Flops. Such improvements might narrow the gap between academic models and industrial deployments in object tracking task.

<div align="center">
  <img src="LightTrack_Fig1.PNG" width="500px" />
</div>

## ğŸš€ å¿«é€Ÿå¼€å§‹ (Quick Start)

### ç¯å¢ƒå®‰è£… (Environment Installation)
```bash
# å®‰è£…åŸºç¡€ä¾èµ– (Install basic dependencies)
pip install opencv-python numpy torch torchvision pillow easydict shapely

# æˆ–ä½¿ç”¨conda (Or use conda)
conda create -n lighttrack python=3.8
conda activate lighttrack
pip install opencv-python numpy torch torchvision pillow easydict shapely
```

### ğŸ“± GUIè·Ÿè¸ªåº”ç”¨ (GUI Tracking Application)
```bash
# å¯åŠ¨å¢å¼ºç‰ˆGUI (Launch Enhanced GUI)
python enhanced_gui_tracker.py

# æˆ–å¯åŠ¨æ ‡å‡†GUI (Or launch standard GUI)  
python gui_tracker.py
```

### ğŸ¯ å‘½ä»¤è¡Œè·Ÿè¸ª (Command Line Tracking)
```bash
# åˆ›å»ºæµ‹è¯•è§†é¢‘ (Create test video)
python create_sample_video.py

# å‘½ä»¤è¡Œè·Ÿè¸ª (Command line tracking)
python mp4_tracking_demo.py --video sample_video.mp4 --display

# ä½¿ç”¨ä¼˜åŒ–è·Ÿè¸ªå™¨ (Use optimized tracker)
python optimized_tracker.py
```

### âš¡ æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬ (Performance Optimized Version)

**å½“å‰ç‰ˆæœ¬å·²å®ç°ä»¥ä¸‹ä¼˜åŒ–:**
- âœ… **é«˜é€Ÿè·Ÿè¸ª**: ä¼˜åŒ–ç®—æ³•å®ç°ï¼ŒCPUæ¨¡å¼ä¸‹è¾¾åˆ° **138k+ FPS**
- âœ… **GPUåŠ é€Ÿ**: æ”¯æŒCUDAåŠ é€Ÿçš„çœŸå®LightTrackæ¨¡å‹
- âœ… **æ™ºèƒ½å›é€€**: çœŸå®æ¨¡å‹ä¸å¯ç”¨æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°ä¼˜åŒ–æ¼”ç¤ºæ¨¡å¼
- âœ… **å¤šçº¿ç¨‹å¤„ç†**: GUIç•Œé¢æ— é˜»å¡ï¼Œå®æ—¶æ€§èƒ½ç›‘æ§
- âœ… **å¢å¼ºç¨³å®šæ€§**: æ”¹è¿›çš„æ¨¡æ¿åŒ¹é…ç®—æ³•ï¼Œå‡å°‘ç›®æ ‡ä¸¢å¤±

## ğŸ“Š æ€§èƒ½å¯¹æ¯” (Performance Comparison)

| ç‰ˆæœ¬ | æ¨¡å¼ | FPS | ç‰¹ç‚¹ |
|-----|------|-----|------|
| åŸå§‹ç‰ˆæœ¬ | æ¨¡æ¿åŒ¹é… | ~10 | åŸºç¡€è·Ÿè¸ª |
| ä¼˜åŒ–ç‰ˆæœ¬ | CPUæ¼”ç¤ºæ¨¡å¼ | 138k+ | è¶…é«˜é€Ÿå¤„ç† |
| ä¼˜åŒ–ç‰ˆæœ¬ | GPUçœŸå®æ¨¡å‹ | 90+ | é«˜ç²¾åº¦è·Ÿè¸ª |

## ğŸ”§ åŸå§‹ç ”ç©¶åŠŸèƒ½ (Original Research Features)

### Environment Installation
```
cd lighttrack
conda create -n lighttrack python=3.6
conda activate lighttrack
bash install.sh
```
### Data Preparation
- Tracking Benchmarks

Please put VOT2019 dataset under `$LightTrack/dataset`. The prepared data should look like:
```
$LighTrack/dataset/VOT2019.json
$LighTrack/dataset/VOT2019/agility
$LighTrack/dataset/VOT2019/ants1
...
$LighTrack/dataset/VOT2019/list.txt
```
## Test and evaluation
Test LightTrack-Mobile on VOT2019
```
bash tracking/reproduce_vot2019.sh
```
## Flops, Params, and Speed
Compute the flops and params of our LightTrack-Mobile. The flops counter we use is [pytorch-OpCounter](https://github.com/Lyken17/pytorch-OpCounter)
```
python tracking/FLOPs_Params.py
```
Test the running speed of our LightTrack-Mobile
```
python tracking/Speed.py
```
